{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install git+https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "id": "dFO_g-NNyvmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok"
      ],
      "metadata": {
        "id": "RrgFQJ6cHBuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
        "from fastapi.responses import JSONResponse\n",
        "from google.colab import userdata\n",
        "from pydantic import BaseModel\n",
        "from fastapi import FastAPI\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import base64\n",
        "import io"
      ],
      "metadata": {
        "id": "fLKkpzz3uAlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageGenerationModel():\n",
        "    \"\"\"\n",
        "    A class for generating images using the Stable Diffusion model.\n",
        "\n",
        "    Attributes:\n",
        "        unet: UNet model for image processing.\n",
        "        pipeline: Diffusion pipeline for generating images using the diffusion model.\n",
        "\n",
        "    Methods:\n",
        "        get_generated_image(): Generates an image based on the given text prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the model by loading the pretrained UNet model and setting up the pipeline for image generation.\n",
        "        \"\"\"\n",
        "        self.unet = UNet2DConditionModel.from_pretrained(\"shshshamilll/unet\")\n",
        "        self.pipeline = DiffusionPipeline.from_pretrained(\n",
        "            \"stable-diffusion-v1-5/stable-diffusion-v1-5\", unet=self.unet\n",
        "        ).to(\"cuda\")\n",
        "        self.pipeline.safety_checker = None\n",
        "\n",
        "    def get_generated_image(self, prompt):\n",
        "        \"\"\"\n",
        "        Generates an image based on the given text prompt.\n",
        "\n",
        "        Parameters:\n",
        "            prompt: The text prompt for generating the image.\n",
        "\n",
        "        Returns:\n",
        "            The generated image.\n",
        "        \"\"\"\n",
        "        generated_image = self.pipeline(\n",
        "            prompt,\n",
        "            negative_prompt=\"Shirt sleeves, black shirt, black background\",\n",
        "            guidance_scale=8.5,\n",
        "            num_inference_steps=100\n",
        "        ).images[0]\n",
        "        return generated_image"
      ],
      "metadata": {
        "id": "-BIPoAcebkhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_authtoken = userdata.get('NGROK_AUTHTOKEN')\n",
        "userdata.get('HF_TOKEN')\n",
        "\n",
        "ngrok.set_auth_token(ngrok_authtoken)\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url.public_url}\")"
      ],
      "metadata": {
        "id": "PN7U-QTLWPgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "image_generation_model = ImageGenerationModel()"
      ],
      "metadata": {
        "id": "W258pu8YWpAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageGenerationRequest(BaseModel):\n",
        "    \"\"\"\n",
        "    Data model for an image generation request.\n",
        "\n",
        "    Attributes:\n",
        "        prompt: A prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt: str\n",
        "\n",
        "def encode_image(image):\n",
        "    \"\"\"\n",
        "    Encodes an image to base64 format.\n",
        "\n",
        "    Parameters:\n",
        "        image: The image to be encoded.\n",
        "\n",
        "    Returns:\n",
        "        The image in base64 format.\n",
        "    \"\"\"\n",
        "    image_buffer = io.BytesIO()\n",
        "    image.save(image_buffer, format=\"PNG\")\n",
        "    return base64.b64encode(image_buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "@app.post(\"/get_remote_generated_image\")\n",
        "def get_remote_generated_image(image_generation_request: ImageGenerationRequest):\n",
        "    \"\"\"\n",
        "    Generates an image on a remote server based on the request and returns it in base64 format.\n",
        "\n",
        "    This function handles the POST request with a prompt, generates the image, and returns it in base64 format.\n",
        "\n",
        "    Parameters:\n",
        "        image_generation_request: The object containing the prompt for image generation.\n",
        "\n",
        "    Returns:\n",
        "        A response containing the image in base64 format.\n",
        "    \"\"\"\n",
        "    remote_generated_image = image_generation_model.get_generated_image(image_generation_request.prompt)\n",
        "    return JSONResponse(content={\"remote_generated_image_in_base64_format\": encode_image(remote_generated_image)})"
      ],
      "metadata": {
        "id": "bBAQR1ir7GyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "id": "OgJM8wUaW3g_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}